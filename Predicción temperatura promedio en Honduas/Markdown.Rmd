---
title: "Predicción de la temperatura promedio en Honduras"
author: "Andrés Dala"
date: "12/11/2021"
output:
  html_document: 
    toc: yes
    toc_float: true
    smooth_scroll : TRUE
    theme: cerulean
    df_print: default
  pdf_document: default
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align = "center")
```

# Introducción

Uno de los ámbitos principales de estudio en las series temporales es la variación del clima. A continuación se predecirá la temperatura promedio en Honduras para el año 2014, esto será utilizando la Metodología de predicción con Modelos SARIMA Bayesianos. El conjunto de datos a estudiar fue extraído de [BERKELEY EARTH](http://berkeleyearth.org/data/), el cual muestra la temperatura promedio del país desde 1980 hasta 2013. En este estudio se propondrán dos modelos distintos elegidos en base al comportamiento observado en los datos y un modelo generado por la función <code>auto.sarima</code> del paquete **bayesforecast**.

```{r}
#install.packages(c("forecast","dplyr","ggplot2","tsibble","bayesforecast",
#                   "cowplot","loo","bayesplot"))
```

```{r, message=FALSE}
library(forecast)
library(dplyr)
library(ggplot2)
library(tsibble)
library(bayesforecast)
library(cowplot)
library(loo)
library(bayesplot)
options(mc.cores = parallel::detectCores())
```

Primero cargamos los datos desde el repositorio en github y luego extraemos únicamente la temperatura promedio de Honduras con sus respectivos datos de tiempo, guardándolos en la variable de tipo <code>ts</code> llamada serie.

```{r}
#datos<-read.csv("C:/Users/Andres Dala/Desktop/LandTemperature.csv")

datos<-read.csv("https://raw.githubusercontent.com/Andres-Dala/Seminario_de_Investigacion_MM700/main/Predicci%C3%B3n%20temperatura%20promedio%20en%20Honduas/LandTemperature.csv")

honduras<-datos %>%
  filter(Country == "Honduras")

honduras$dt<-as.Date(honduras$dt)
honduras <- honduras %>%
  filter(as.numeric(format(dt,"%Y"))>=1980)
honduras <- honduras %>%
  select(dt, AverageTemperature)

serie<-ts(honduras$AverageTemperature, frequency = 12, start = 1980)
```

Luego partimos el conjunto de datos *serie* en dos partes, el primero será el conjunto de entrenamiento que incluirá el 95% de las primeras observaciones guardado en la variable <code>train</code> y el resto será el conjunto de prueba guardado como <code>test</code>. De ahora en adelante nos referiremos a <code>train</code> como la serie.

```{r}
train = head(serie, round(length(serie) * 0.95))
h = length(serie) - length(train)
test = tail(serie, h)
```

# Visualización de los datos

El primer paso es graficar la serie para identificar algún tipo de patrón y comportamiento en ellos:

```{r, fig.width=9, fig.height=4}
autoplot(object = train, main = "Temperatura promedio en Honduras", ylab="Celsius", xlab = "Años")
```

Se puede observar en la figura anterior que existe un comportamiento estacional lo cual es lógico dada la naturaleza de las observaciones, de esta manera para observar los periodos de manera explicita generamos un gráfico estacional:

```{r}
tsibble::as_tsibble(train) %>%
  feasts::gg_season(value) +
  labs(x = "", y = "Celsius", title = "Grafico estacional") +
   theme(axis.text.x = element_text(angle = 90))
```

En el gráfico estacional se observa que el periodo es anualmente ósea 12 meses lo cual concuerda con el hecho que los datos son observaciones climatológicas. Luego, una vez identificados los patrones y verificado la no estacionaridad en la serie se propone hacer una diferenciación estacional de orden 12 y observar si el resultado necesita de una segunda diferenciación.

```{r}
cbind("Celsius" = train,
      "Diferenciada\n estacionalmente" = diff(train,12),
      "Doblemente\n diferenciada" = diff(diff(train,12))) %>%
  autoplot(facets = TRUE) +
  xlab("Años") + ylab("") 
```

Como podemos observar en la figura anterior, al aplicar una diferenciación estacional la serie aún no luce estacionaria dado que la media no parece ser constante sin embargo la estacionalidad ya no se observa lo que indica que basta hacer una segunda diferenciación en este caso no estacional y como se observa en la ultima gráfica la serie parece tener una media constante en cero y una varianza igualmente estable. Por otra parte, una vía más sencilla y objetiva de estar seguros de la estacionaridad podemos graficar las funciones de autocorrelación y autocorrelación parcial:

```{r}
g2 = ggacf(y = diff(diff(train,12)))
g3 = ggpacf(y = diff(diff(train,12)))

gridExtra::grid.arrange(g2,g3, ncol = 2)
```

Se puede apreciar en ambos gráficos (ACF y PACF) que los retardos (lags) no tiene un comportamiento descendente sino que rápidamente se acercan a cero desde los primeros valores lo cual es indicativo de estacionaridad.

# Modelo 1

## Selección del modelo

Observando los gráficos ACF y PACF notamos que existe una fuerte correlación en al menos dos retardos (ACF) lo que podemos interpretar como un modelo ARIMA con $p=2$, $d=1$, $q=2$. Por otra parte se observa un claro comportamiento periódico cada 12 retardos iniciando en el retardo 12 de esta manera incluimos la parte estacional del como $P=2$, $D=1$, $Q=0$. También consideramos distribuciones a priori poco informativas, esto es usando las prioris por defecto para el parámetro locacional $\mu_0$, escala $\sigma_0$ y los parámetros autorregresivos y de medias móviles. Como resultado el modelo completo es: 

$$
 Temperatura \sim SARIMA(2,1,2)_\times(2,1,0)_{12}\\
 \mu_0 \sim t(0,2.5,6)\\
 \sigma_0 \sim t(7)\\
 ar_1, ma_1 \sim N(0,0.5)\\
 sar_1,sma_1 \sim N(0,0.5)
$$

Para la inferencia y análisis de los modelos  utilizaremos el paquete \textit{bayesforecast} con los parámetros por defecto, esto es, generando 4 cadenas con un tamaño de muestra de 2,000 y un warmup de 1,000 iteraciones. Como diagnóstico de convergencia usaremos el estadístico $\hat{R}$ y revisaremos los ESS.

## Ajuste el modelo 1

```{r}
sf1<-stan_sarima(train, order = c(2,1,2), seasonal = c(2,1,0))
```

```{r}
sf1
```

## Evaluación de la inferencia 

Al observar el estadístico $\hat{R}$ de cada uno de los parámetros se puede concluir que estos convergen ya que todos son menores a 1.1 y además los tamaños de simulaciones suficientes para obtener representar la información (ESS) son grandes lo cual comprueban una tendencia a converger. También podemos visualizar estas simulaciones con el paquete **bayesplot** para asegurarnos de no dejar pasar ningún comportamiento extraño en las cadenas. 

```{r,fig.height=10}
sf1Pars = data.frame(extract_stan(sf1,pars = c("mu0","sigma0","ar","ma","sar")))
sf1Pars = cbind(Chain = sort(rep(1:4,1000)),sf1Pars)

mcmc_combo(sf1Pars)
```

Se observa que las cadenas tienden a un comportamiento convergente, además no se observa multimodalidad en la distribución de los parámetros por lo tanto podemos aceptar las estimaciones del modelo y podemos continuar con el diagnóstico del ajuste en los datos.

## Diagnóstico del modelo 

El paso determinante si el modelo es factible o no, es el determinar el comportamiento de los residuos del modelo dado que los modelos SARIMA siguen el supuesto que los errores siguen un ruido blanco Gaussiano, es decir, los errores son estacionarios con distribución normal, de esta manera usamos la función <code>check_residuals</code> la cual estima la media a posteriori de los residuos y luego graficándolos como se muestra a continuación:

```{r}
check_residuals(sf1) 
```

Podemos observar en el histograma y gráfico de cuantiles (parte de en medio) que los residuos no tiene colas pesadas esto por la baja volatilidad de la serie lo que indica normalidad. Las gráficos ACF y PACF muestran una baja correlación manteniéndose de los intervalos lo que indica estacionaridad. Por último podemos observar la distribución de los residuos:

```{r}
Residuals1 = predictive_error(sf1)
Residuals1 = Residuals1[1:100,]

ppc_dens_overlay(y = rnorm(385),yrep = data.matrix(Residuals1))
```

Como se observa en la figura anterior la distribución de los errores sigue una distribución normal por lo tanto podemos aceptar el ajuste que hace el modelo. Para observar como se comportan los datos reales junto con una simulación predictiva a posteriori generada del modelo podemos observar la siguiente gráfica:

```{r, fig.width=9, fig.height=4}
autoplot(sf1)+labs(title = "Verificación Predictiva a Posteriori", y="Celsius", x = "Años")
```

Finalmente, luego que las pruebas diagnósticas fueran exitosas podemos creer que tenemos un modelo factible, sin embargo podemos hacernos la pregunta que ocurre si proponemos distribuciones a priori distintas para los modelos autorregresivos y de medias móviles además de modificar los parámetros del modelo SARIMA, esto resultando de la siguiente manera:

# Modelo 2

## Selección del modelo

$$
 Temperatura \sim SARIMA(1,1,0)_\times(1,1,1)_{12}\\
 \mu_0 \sim t(0,2.5,6)\\
 \sigma_0 \sim t(7)\\
 ar_1, ma_1 \sim beta(2,2)\\
 sar_1,sma_1 \sim beta(2,2)
$$

## Ajuste del modelo 

```{r, results='hide', warning=FALSE}
sf2<-stan_sarima(train, order = c(1,1,0), seasonal = c(1,1,1),
                  prior_ar = beta(2,2),prior_ma = beta(2,2),
                  prior_sar = beta(2,2),prior_sma = beta(2,2))
```

## Evaluación de la inferencia

```{r}
sf2
```

Para la inferencia generada por el segundo modelo se muestra que los parámetros cumplen con los estadísticos de convergencia.

```{r,fig.height=10}
sf2Pars = data.frame(extract_stan(sf2,pars = c("mu0","sigma0","ar","sar","sma")))
sf2Pars = cbind(Chain = sort(rep(1:4,1000)),sf2Pars)

mcmc_combo(sf2Pars)

```

Observamos que las cadenas tienen un comportamiento convergente y se entrelazan correctamente al igual que las distribuciones no muestran multimodalidad de esta manera podemos aceptar la inferencia del modelo.

## Diagnóstico del modelo 

```{r}
check_residuals(sf2)
```

A diferencia del primero modelo observamos que el modelo de los errores muestran ciertas colas pesadas (gráficos de en medio) sin embargo la autocorrelación (gráficos inferiores) se muestra baja indicando estacionaridad, luego graficando la distribución obtenemos:

```{r}
Residuals2 = predictive_error(sf2)
Residuals2 = Residuals2[1:100,]

ppc_dens_overlay(y = rnorm(385),yrep = data.matrix(Residuals2))
```

La gráfico de la distribución muestra un comportamiento normal de esta manera podemos aceptar el modelo como factible. Podemos ver el ajuste del mismo en la siguiente figura: 

```{r, fig.width=9, fig.height=4}
autoplot(sf2)+labs(title = "Verificación Predictiva a Posteriori", y="Celsius", x = "Años")
```

# Modelo 3

Ahora estudiaremos un tercer modelo el cual lo vamos a generar con la función <code>auto.sarima</code> el cual genera los parámetros del modelo SARIMA y hace la respectiva inferencia.

## Selección y ajuste del modelo

```{r}
sf3<-auto.sarima(train)
prior_summary(sf3)
```

Podemos observar que a diferencia de los otros dos modelos este solo aplica una diferencia estacional y no indica necesaria la presencia de modelos de medias móviles, mientras que las distribuciones a priori se mantienen igual.

## Evaluación de la inferencia

```{r}
sf3
```

De igual manera los estadísticos de los parámetros son aceptables.

```{r,fig.height=10}
sf3Pars = data.frame(extract_stan(sf3,pars = c("mu0","sigma0","ar","ma","sar","sma")))
sf3Pars = cbind(Chain = sort(rep(1:4,1000)),sf3Pars)

mcmc_combo(sf3Pars)

```

Igualmente las distribuciones no presentan multimodalidad y las cadenas se acomplan correctamente por lo que aceptamos la inferencia del modelo.

## Diagnóstico del modelo

```{r}
check_residuals(sf3)
```

Si recordamos en este tercer modelo solo se realizó una diferenciación estacional y como resultado podemos observar en la serie de los residuos (gráfico superior) que existe cierta periodicidad en los errores además si observamos el gráfico PACF también se muestra cierta comportamiento periódico por tanto una diferenciación estacional no fue suficiente para el modelo.

```{r}
Residuals3 = predictive_error(sf3)
Residuals3 = Residuals3[1:100,]

ppc_dens_overlay(y = rnorm(385),yrep = data.matrix(Residuals3))
```

Al observar la distribución de los errores vemos comportamiento normal por lo que aceptaremos el modelo siempre tomando en cuenta que no presentó los resultados esperados en cuanto a la estacionaridad.

```{r, fig.width=9, fig.height=4}
autoplot(sf3)+labs(title = "Verificación Predictiva a Posteriori", y="Celsius", x = "Años")
```

# Comparación de los modelos

Finalmente procedemos a comparar los modelos mediante la función <code>loo</code> el cual compara la precisión de cada modelo con CV-LOO   *leave-one-out cross-validation* extrayendo el elpd (*expected log pointwise predictive density*). Para empezar intentaremos generar una predicción con cada uno de los modelos intentando simular el conjunto de prueba. Podemos las predicciones en la siguiente gráfica:

```{r}
forecast1<-forecast(sf1, h = 20)
pred<-ts(forecast1$mean, frequency = 12, start = c(2012,2))
forecast2<-forecast(sf2, h = 20)
pred2<-ts(forecast2$mean, frequency = 12, start = c(2012,2))
forecast3<-forecast(sf3, h = 20)
pred3<-ts(forecast3$mean, frequency = 12, start = c(2012,2))

co<-data.frame("Modelo 1" = pred, "Modelo 2" = pred2, 
               "Modelo 3" = pred3, "C Prueba" = test)

comb<-ts(co, frequency = 12, start = c(2012,2))

autoplot(comb[,c("Modelo.1", "Modelo.2","Modelo.3", "C.Prueba")]) +
  ylab("Celsius") + xlab("Años") + xlim(2012,2014)

```

Se puede observar que los tres modelos generaron una predicción bastante cercana al conjunto de prueba sin embargo a simple vista no podemos determinar cual es el mejor modelo por tanto procedemos a hacer la comparación:

```{r}
loo1 = loo(sf1)
loo2 = loo(sf2)
train2<-ts(train[-1], frequency = 12, start = c(1980,2))
sf3<-stan_sarima(train2, order = c(1,0,0), seasonal = c(1,1,0))
loo3<-loo(sf3)
loo_compare(loo1,loo2,loo3)
```

La tabla anterior nos indica que el modelo que mejor predice los valores es el primero y que el tercero es el que peor precisión tiene, lo cual desde las pruebas anteriores venia siendo una leve intuición pero con esta prueba lo comprobamos. De esta manera el modelo uno es el seleccionado para proceder a hacer la predicción final de los datos desconocidos. El conjunto total nos muestra observaciones hasta el mes de septiembre del 2013 así que vamos a predecir los siguientes 15 meses ósea hasta diciembre del 2015.

# Predicción

```{r, message=FALSE, warning=FALSE}
sf4<-stan_sarima(serie, order = c(2,1,2), seasonal = c(2,1,0))

ff<-forecast(sf4,15)

autoplot(ff)  + labs(title = "Predicción final", y = "Celsius", x = "Años")  +
  xlim(2010,2015)
```
